"""
Example usage of the Unified Agent with API-based LLM
Demonstrates how to interact with the agent programmatically
"""

import asyncio
import sys
import os
from dotenv import load_dotenv

# Add parent directory to path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.agent import UnifiedAgent
from src.rag.llm_engine import LLMEngine
from src.rag.document_processor import VectorStore

# Load environment variables from .env file
load_dotenv()


async def main():
    """Example usage of the unified agent"""
    
    # Configuration
    config = {
        "models": {
            "binary_classifier": {
                "enabled": True,
                "checkpoint_path": "weights/binary_classifier.pth",
                "model_type": "swin_transformer"
            },
            "multiclass_classifier": {
                "enabled": True,
                "checkpoint_path": "weights/fourteen_class_classifier",
                "num_classes": 14,
                "model_type": "swin_transformer"
            },
            "rag": {
                "enabled": True,
                # LLM Provider: 'openai', 'anthropic', or 'gemini'
                "llm_provider": os.getenv("LLM_PROVIDER", "openai"),
                # Model name (optional, uses defaults if not specified)
                "model_name": os.getenv("LLM_MODEL_NAME", None),
                # API key (optional, reads from environment if not specified)
                "api_key": None,  # Will use OPENAI_API_KEY, ANTHROPIC_API_KEY, or GOOGLE_API_KEY from .env
                # Generation parameters
                "max_tokens": int(os.getenv("LLM_MAX_TOKENS", "2048")),
                "temperature": float(os.getenv("LLM_TEMPERATURE", "0.7")),
                # Vector database configuration
                "vector_db_path": "rag_pipeline/chroma_db",
                "documents_path": "dataset/books"
            }
        },
        "device": "cuda"
    }
    
    print("ğŸš€ Initializing Unified CXR Agent with API-based LLM...")
    print(f"   LLM Provider: {config['models']['rag']['llm_provider']}")
    
    # Initialize components
    vector_store = VectorStore(collection_name="respiratory_care_docs")
    llm_engine = LLMEngine(
        provider=config["models"]["rag"]["llm_provider"],
        model_name=config["models"]["rag"]["model_name"],
        api_key=config["models"]["rag"]["api_key"],
        max_tokens=config["models"]["rag"]["max_tokens"],
        temperature=config["models"]["rag"]["temperature"]
    )
    
    # Create unified agent
    agent = UnifiedAgent(
        config=config,
        llm_engine=llm_engine,
        vector_store=vector_store
    )
    
    print("âœ… Agent initialized!\n")
    
    # Example 1: Ask a medical question (no image)
    print("=" * 80)
    print("Example 1: Medical Question (No Image)")
    print("=" * 80)
    
    response = await agent.process_message(
        query="What are the radiological signs of pneumonia on a chest X-ray?"
    )
    
    print(f"\nğŸ“ Question: What are the radiological signs of pneumonia on a chest X-ray?")
    print(f"\nğŸ¤– Answer:\n{response['answer']}")
    
    if response.get('has_thinking'):
        print(f"\nğŸ§  AI Thinking:\n{response['thinking'][:200]}...")
    
    if response.get('sources'):
        print(f"\nğŸ“š Sources: {len(response['sources'])} medical references")
    
    print("\n")
    
    # Example 2: Analyze an image with a question
    print("=" * 80)
    print("Example 2: Image Analysis + Question")
    print("=" * 80)
    
    # Note: Replace with actual image path
    image_path = "path/to/your/chest_xray.jpg"
    
    response = await agent.process_message(
        query="Is this chest X-ray normal or abnormal? What diseases can you detect?",
        image_path=image_path  # Comment this out if you don't have an image
    )
    
    print(f"\nğŸ“ Question: Is this chest X-ray normal or abnormal? What diseases can you detect?")
    print(f"ğŸ–¼ï¸  Image: {image_path}")
    
    if response.get('image_analysis'):
        print(f"\nğŸ” Image Analysis Results:")
        binary = response['image_analysis'].get('binary')
        if binary:
            print(f"   Binary Classification: {binary['prediction']} ({binary['confidence']:.1%})")
        
        diseases = response['image_analysis'].get('diseases')
        if diseases and diseases.get('detected_diseases'):
            print(f"   Detected Diseases:")
            for disease, prob in diseases['detected_diseases'].items():
                print(f"      - {disease}: {prob:.1%}")
    
    print(f"\nğŸ¤– Answer:\n{response['answer']}")
    print("\n")
    
    # Example 3: Follow-up question about the image
    print("=" * 80)
    print("Example 3: Follow-up Question (Using Previous Image Context)")
    print("=" * 80)
    
    response = await agent.process_message(
        query="What is the clinical significance of these findings?"
    )
    
    print(f"\nğŸ“ Question: What is the clinical significance of these findings?")
    print(f"\nğŸ¤– Answer:\n{response['answer']}")
    print("\n")
    
    # Example 4: Check conversation history
    print("=" * 80)
    print("Example 4: Conversation History")
    print("=" * 80)
    
    history = agent.get_conversation_history()
    print(f"\nğŸ“Š Total conversations: {len(history)}")
    
    for i, conv in enumerate(history, 1):
        print(f"\n--- Conversation {i} ---")
        print(f"Query: {conv['query'][:60]}...")
        print(f"Has Image: {conv['has_image']}")
        print(f"Intent Type: {conv['intent']['type']}")
        print(f"Timestamp: {conv['timestamp']}")
    
    # Example 5: Clear history
    print("\n" + "=" * 80)
    print("Example 5: Clear History")
    print("=" * 80)
    
    agent.clear_history()
    print("âœ… Conversation history cleared")
    print(f"ğŸ“Š Total conversations now: {len(agent.get_conversation_history())}")
    
    print("\n" + "=" * 80)
    print("âœ… All examples completed!")
    print("=" * 80)


if __name__ == "__main__":
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                              â•‘
    â•‘        CXR Agent - Unified Conversational Interface         â•‘
    â•‘                                                              â•‘
    â•‘  A single LLM-powered interface for:                        â•‘
    â•‘  â€¢ Chest X-ray analysis                                     â•‘
    â•‘  â€¢ Medical knowledge Q&A                                    â•‘
    â•‘  â€¢ Combined image + knowledge queries                       â•‘
    â•‘                                                              â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Goodbye!")
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
